```
import warnings
from glob import glob

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import wqet_grader
from category_encoders import OneHotEncoder # New for this lession
from IPython.display import VimeoVideo
from sklearn.linear_model import LinearRegression, Ridge  # noqa F401 New for this lession
from sklearn.metrics import mean_absolute_error
from sklearn.pipeline import make_pipeline
from sklearn.utils.validation import check_is_fitted  # New for this lession

warnings.simplefilter(action="ignore", category=FutureWarning)

def wrangle(filepath):
    # Read CSV file
    df = pd.read_csv(filepath)

    # Subset data: Apartments in "Capital Federal", less than 400,000
    mask_ba = df["place_with_parent_names"].str.contains("Capital Federal")
    mask_apt = df["property_type"] == "apartment"
    mask_price = df["price_aprox_usd"] < 400_000
    df = df[mask_ba & mask_apt & mask_price]

    # Subset data: Remove outliers for "surface_covered_in_m2"
    low, high = df["surface_covered_in_m2"].quantile([0.1, 0.9])
    mask_area = df["surface_covered_in_m2"].between(low, high)
    df = df[mask_area]

    # Split "lat-lon" column
    df[["lat", "lon"]] = df["lat-lon"].str.split(",", expand=True).astype(float)
    df.drop(columns="lat-lon", inplace=True)
    
     # Pull neighborhood
    df["neighborhood"] = df["place_with_parent_names"].str.split("|",expand = True)[3]
    df.drop(columns ="place_with_parent_names",inplace = True)
    
    return df
    
  ## Task 2.3.1     
  files = glob("data/buenos-aires-real-estate-*.csv") :

 # Task 2.3.3
frames = []
      for file in files:
        df = wrangle(file)
       frames.append(df)  
       
df = pd.concat(frames,ignore_index = True)
    df.shape
    
# Task 2.3.4    
df["neighborhood"] = df["place_with_parent_names"].str.split("|",expand = True)[3] 
    df.drop(columns ="place_with_parent_names",inplace = True)
    
# Task 2.3.5
target = "price_aprox_usd"
    features = ["neighborhood"]
    y_train = df[target]
    X_train = df[features]
    
#Task 2.3.6
y_mean = y_train.mean()
   y_pred_baseline = [y_mean] * len(y_train)
  print("Mean apt price:", y_mean)
  print("Baseline MAE:", mean_absolute_error(y_train,y_pred_baseline))
  
# Task 2.3.7
ohe = OneHotEncoder(use_cat_names = True)
ohe.fit(X_train)
XT_train = ohe.transform(X_train)
print(XT_train.shape)
XT_train.head()

# Task 2.3.8
ohe = OneHotEncoder(use_cat_names = True)
ohe.fit(X_train)
XT_train = ohe.transform(X_train)
print(XT_train.shape)
XT_train.head()

model = make_pipeline(
    OneHotEncoder(use_cat_names=True),
    LinearRegression()
)
model.fit(X_train,y_train)

# Task 2.3.9
y_pred_training = model.predict(X_train)
mae_training = mean_absolute_error(y_train,y_pred_training)
print("Training MAE:", round(mae_training, 2))

# Task 2.3.10
X_test = pd.read_csv("data/buenos-aires-test-features.csv")[features]
y_pred_test = pd.Series(model.predict(X_test))
y_pred_test.head()

# Task 2.3.11
intercept = model.named_steps["linearregression"].intercept_
coefficients = model.named_steps["linearregression"].coef_
print("coefficients len:", len(coefficients))
print(coefficients[:5])  # First five coefficients

# Task 2.3.12
feature_names = model.named_steps["onehotencoder"].get_feature_names()
print("features len:", len(feature_names))
print(feature_names[:5])  # First five feature names

# Task 2.3.13
feat_imp = pd.Series(coefficients,index=feature_names)
feat_imp.head()

print(f"price = {intercept.round(2)}")
for f, c in feat_imp.items():
    print(f"+ ({round(c, 2)} * {f})")
    
# Task 2.3.15
model = make_pipeline(
    OneHotEncoder(use_cat_names=True),
    Ridge()
)
model.fit(X_train,y_train)

intercept = model.named_steps["ridge"].intercept_
coefficients = model.named_steps["ridge"].coef_
print("coefficients len:", len(coefficients))
print(coefficients[:5])  # First five coefficients

# Task 2.3.16
based on their absolute value.
feat_imp.sort_values(key=abs).tail(15).plot(kind="barh")
plt.xlabel("Importance [USD]")
plt.ylabel("Feature")
plt.title("Feature Importance for Apartment Price")

  



```

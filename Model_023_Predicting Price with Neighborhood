```
## 023 Predicting Price with Neighborhood

import warnings
from glob import glob

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import wqet_grader
from category_encoders import OneHotEncoder # New for this lession
from IPython.display import VimeoVideo
from sklearn.linear_model import LinearRegression, Ridge  # noqa F401 New for this lession
from sklearn.metrics import mean_absolute_error
from sklearn.pipeline import make_pipeline
from sklearn.utils.validation import check_is_fitted  # New for this lession

warnings.simplefilter(action="ignore", category=FutureWarning)
wqet_grader.init("Project 2 Assessment")

In the last lesson, we created a model that used location — represented by latitude and longitude — to predict price. 
In this lesson, we're going to use a different representation for location: neighborhood.

### Prepare Data
#### Import

def wrangle(filepath):
    # Read CSV file
    df = pd.read_csv(filepath)

    # Subset data: Apartments in "Capital Federal", less than 400,000
    mask_ba = df["place_with_parent_names"].str.contains("Capital Federal")
    mask_apt = df["property_type"] == "apartment"
    mask_price = df["price_aprox_usd"] < 400_000
    df = df[mask_ba & mask_apt & mask_price]

    # Subset data: Remove outliers for "surface_covered_in_m2"
    low, high = df["surface_covered_in_m2"].quantile([0.1, 0.9])
    mask_area = df["surface_covered_in_m2"].between(low, high)
    df = df[mask_area]

    # Split "lat-lon" column
    df[["lat", "lon"]] = df["lat-lon"].str.split(",", expand=True).astype(float)
    df.drop(columns="lat-lon", inplace=True)
    
     # Pull neighborhood
    df["neighborhood"] = df["place_with_parent_names"].str.split("|",expand = True)[3]
    df.drop(columns ="place_with_parent_names",inplace = True)
    

    

    return df
    
    #### Task 2.3.1:
    Use glob to create a list that contains the filenames for all the Buenos Aires 
    real estate CSV files in the data directory.    Assign this list to the variable name files.
    
    files = glob("data/buenos-aires-real-estate-*.csv")
    
    #### Task 2.3.2:** Use your `wrangle` function in a `for` loop to create a list named `frames`. 
    The list should the cleaned DataFrames created from the CSV filenames your collected in `files`
    
      frames = []
      for file in files:
        df = wrangle(file)
       frames.append(df)
    
    #### Task 2.3.3: Use pd.concat to concatenate the items in frames into a single DataFrame
    
    df = pd.concat(frames,ignore_index = True)
    df.shape
    
    ### Explore
    #### Task 2.3.4: Modify your wrangle function to create a new feature "neighborhood".
    
     # Pull neighborhood
    df["neighborhood"] = df["place_with_parent_names"].str.split("|",expand = True)[3]
    df.drop(columns ="place_with_parent_names",inplace = True)
    
    
    ## Split
    #### Task 2.3.5: Create your feature matrix X_train and target vector y_train. 
    At this point, you should feel more comfortable with the splitting data, 
    so we're going to condense the whole process down to one task.
    
    target = "price_aprox_usd"
    features = ["neighborhood"]
    y_train = df[target]
    X_train = df[features]
    
    ## Build Model
    #### Task 2.3.6: Calculate the baseline mean absolute error for your model.
    
    y_mean = y_train.mean()
   y_pred_baseline = [y_mean] * len(y_train)
  print("Mean apt price:", y_mean)
  print("Baseline MAE:", mean_absolute_error(y_train,y_pred_baseline))
  
  ## Iterate
  #### Task 2.3.7: First, instantiate a OneHotEncoder named ohe
  
ohe = OneHotEncoder(use_cat_names = True)
ohe.fit(X_train)
XT_train = ohe.transform(X_train)
print(XT_train.shape)
XT_train.head()

#### Task 2.3.8: Create a pipeline named model that contains a OneHotEncoder transformer and
a LinearRegression predictor. Then fit your model to the training data.

ohe = OneHotEncoder(use_cat_names = True)
ohe.fit(X_train)
XT_train = ohe.transform(X_train)
print(XT_train.shape)
XT_train.head()

model = make_pipeline(
    OneHotEncoder(use_cat_names=True),
    LinearRegression()
)
model.fit(X_train,y_train)

## Evaluate
Regardless of how you build your model, the evaluation step stays the same. 
Let's see how our model performs with the training set.

#### Task 2.3.9: First, create a list of predictions for the observations in your feature matrix X_train. 
Name this list y_pred_training.

y_pred_training = model.predict(X_train)
mae_training = mean_absolute_error(y_train,y_pred_training)
print("Training MAE:", round(mae_training, 2))

#### Task 2.3.10: Run the code below to import your test data buenos-aires-test-features.csv
(trick question)
X_test = pd.read_csv("data/buenos-aires-test-features.csv")[features]
y_pred_test = pd.Series(model.predict(X_test))
y_pred_test.head()

#### Task 2.3.11: Extract the intercept and coefficients for your model.

intercept = model.named_steps["linearregression"].intercept_
coefficients = model.named_steps["linearregression"].coef_
print("coefficients len:", len(coefficients))
print(coefficients[:5])  # First five coefficients

#### Task 2.3.12: Extract the feature names of your encoded data from the OneHotEncoder in your model.

feature_names = model.named_steps["onehotencoder"].get_feature_names()
print("features len:", len(feature_names))
print(feature_names[:5])  # First five feature names

#### Task 2.3.13: Create a pandas Series named feat_imp where the index is your features and the values are your coefficients.
feat_imp = pd.Series(coefficients,index=feature_names)
feat_imp.head()

print(f"price = {intercept.round(2)}")
for f, c in feat_imp.items():
    print(f"+ ({round(c, 2)} * {f})")
    
#### Task 2.3.15:(ref 2.3.8) Scroll up, change the predictor in your model to Ridge, and retrain it

model = make_pipeline(
    OneHotEncoder(use_cat_names=True),
    Ridge()
)
model.fit(X_train,y_train)

intercept = model.named_steps["ridge"].intercept_
coefficients = model.named_steps["ridge"].coef_
print("coefficients len:", len(coefficients))
print(coefficients[:5])  # First five coefficients

#### Task 2.3.16: Create a horizontal bar chart that shows the top 15 coefficients for your model, 
based on their absolute value.
feat_imp.sort_values(key=abs).tail(15).plot(kind="barh")
plt.xlabel("Importance [USD]")
plt.ylabel("Feature")
plt.title("Feature Importance for Apartment Price")
```
